#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Road Marking Classifier - Enhanced White Line Extraction System
é“è·¯æ¨™ç¤ºåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - æ”¹å–„ç‰ˆç™½ç·šæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ 

This system automatically classifies and color-codes road markings including:
- Crosswalk stripes (æ¨ªæ–­æ­©é“)
- Stop lines (åœæ­¢ç·š) 
- Lane markings/Sidewalk lines (è»Šç·š/æ­©é“ç·š)

Based on research4.ipynb from Trust_Project02
"""

import open3d as o3d
import numpy as np
import ezdxf
import cv2
import os
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from pathlib import Path
import alphashape
from shapely.geometry import Polygon, MultiPolygon
import math
import argparse
import json
from datetime import datetime


class EnhancedWhiteLineExtractor:
    """
    æ”¹å–„ç‰ˆç™½ç·šæŠ½å‡ºã‚¯ãƒ©ã‚¹ - é“è·¯æ¨™ç¤ºã®è‡ªå‹•åˆ†é¡ãƒ»è‰²åˆ†ã‘å‡ºåŠ›ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, config_path=None):
        """
        åˆæœŸåŒ–
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        self.config = {
            # RANSACå¹³é¢æ¤œå‡º
            'ransac': {
                'distance_threshold': 0.1,
                'ransac_n': 3,
                'num_iterations': 1000
            },
            
            # ç›¸å¯¾é«˜ã•åˆ†é¡
            'height': {
                'road_surface_tolerance': 0.05,  # Â±5cm
                'curb_height_range': [0.05, 0.25]  # 5-25cm
            },
            
            # HSVè‰²ç©ºé–“ã«ã‚ˆã‚‹ç™½ç·šæ¤œå‡º
            'hsv': {
                's_range': [0, 30],      # å½©åº¦: ä½å½©åº¦ï¼ˆç™½ã£ã½ã„ï¼‰
                'v_range': [180, 255]    # æ˜åº¦: é«˜æ˜åº¦ï¼ˆæ˜ã‚‹ã„ï¼‰
            },
            
            # RGBé–¾å€¤ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
            'rgb_threshold': 0.58,
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            'clustering': {
                'eps': 0.4,
                'min_samples': 15
            },
            
            # å½¢æ…‹å­¦çš„å‡¦ç†
            'morphology': {
                'erosion_radius': 0.3,
                'erosion_neighbors': 10,
                'dilation_radius': 0.5
            },
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            'vectorization': {
                'min_length': 1.0,
                'aspect_ratio_threshold': 5.0,
                'linearity_threshold': 0.8
            },
            
            # é“è·¯æ¨™ç¤ºåˆ†é¡
            'classification': {
                'crosswalk_min_aspect_ratio': 1.5,
                'crosswalk_max_aspect_ratio': 8.0,
                'stop_line_min_aspect_ratio': 10.0,
                'stop_line_angle_tolerance': 15.0,
                'stop_line_distance_threshold': 5.0
            },
            
            # DXFå‡ºåŠ›è¨­å®š
            'dxf_layers': {
                'crosswalk': {'name': 'CROSSWALK_STRIPES', 'color': 6},  # ãƒã‚¼ãƒ³ã‚¿
                'stop_line': {'name': 'STOP_LINES', 'color': 2},         # é»„è‰²
                'lane': {'name': 'LANES', 'color': 3},                   # ç·‘è‰²
                'curb': {'name': 'CURBS', 'color': 1},                   # èµ¤è‰²
                'metadata': {'name': 'METADATA', 'color': 7}             # ç™½è‰²
            }
        }
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
        if config_path and os.path.exists(config_path):
            self.load_config(config_path)
        
        print("EnhancedWhiteLineExtractor ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    
    def load_config(self, config_path):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                self.config.update(user_config)
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
        except Exception as e:
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def detect_road_plane(self, pcd):
        """
        RANSACã«ã‚ˆã‚‹é“è·¯å¹³é¢æ¤œå‡º
        """
        print("\n=== STEP 1: RANSACé“è·¯å¹³é¢æ¤œå‡º ===")
        
        plane_model, road_indices = pcd.segment_plane(
            distance_threshold=self.config['ransac']['distance_threshold'],
            ransac_n=self.config['ransac']['ransac_n'],
            num_iterations=self.config['ransac']['num_iterations']
        )
        
        road_layer_pcd = pcd.select_by_index(road_indices)
        print(f"é“è·¯å¹³é¢ã‚’æ¤œå‡º: {len(road_indices)} ç‚¹")
        
        return plane_model, road_layer_pcd
    
    def classify_by_height(self, pcd, plane_model):
        """
        åŸºæº–å¹³é¢ã‹ã‚‰ã®ç›¸å¯¾é«˜ã•ã«ã‚ˆã‚‹åˆ†é¡
        """
        print("\n=== STEP 2: ç›¸å¯¾é«˜ã•ã«ã‚ˆã‚‹åˆ†é¡ ===")
        
        points = np.asarray(pcd.points)
        a, b, c, d = plane_model
        
        # å„ç‚¹ã®å¹³é¢ã‹ã‚‰ã®ç¬¦å·ä»˜ãè·é›¢
        distances = points.dot(np.array([a, b, c])) + d
        
        # é«˜ã•ã«åŸºã¥ãåˆ†é¡
        road_surface_mask = np.abs(distances) <= self.config['height']['road_surface_tolerance']
        curb_mask = ((distances > self.config['height']['curb_height_range'][0]) & 
                    (distances < self.config['height']['curb_height_range'][1]))
        
        road_surface_pcd = pcd.select_by_index(np.where(road_surface_mask)[0])
        curbs_pcd = pcd.select_by_index(np.where(curb_mask)[0])
        
        print(f"é“è·¯è¡¨é¢: {len(road_surface_pcd.points)} ç‚¹")
        print(f"ç¸çŸ³: {len(curbs_pcd.points)} ç‚¹")
        
        return road_surface_pcd, curbs_pcd
    
    def extract_white_lines_hsv(self, pcd):
        """
        HSVè‰²ç©ºé–“ã«ã‚ˆã‚‹ç™½ç·šæ¤œå‡º
        """
        print("\n=== STEP 3: HSVè‰²ç©ºé–“ç™½ç·šæ¤œå‡º ===")
        
        if not pcd.has_colors() or len(pcd.points) == 0:
            print("ã‚«ãƒ©ãƒ¼æƒ…å ±ãŒãªã„ãŸã‚ã€RGBé–¾å€¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return self.extract_white_lines_rgb_fallback(pcd)
        
        colors_rgb = np.asarray(pcd.colors)
        colors_bgr = (colors_rgb * 255).astype(np.uint8)[:, ::-1]
        colors_hsv = cv2.cvtColor(np.array([colors_bgr]), cv2.COLOR_BGR2HSV)[0]
        
        # HSVç¯„å›²ã«ã‚ˆã‚‹ç™½ç·šãƒã‚¹ã‚¯
        white_mask = ((colors_hsv[:, 1] >= self.config['hsv']['s_range'][0]) & 
                     (colors_hsv[:, 1] <= self.config['hsv']['s_range'][1]) &
                     (colors_hsv[:, 2] >= self.config['hsv']['v_range'][0]) & 
                     (colors_hsv[:, 2] <= self.config['hsv']['v_range'][1]))
        
        white_points_pcd = pcd.select_by_index(np.where(white_mask)[0])
        asphalt_pcd = pcd.select_by_index(np.where(~white_mask)[0])
        
        print(f"HSVç™½ç·šæ¤œå‡º: {len(white_points_pcd.points)} ç‚¹")
        print(f"ã‚¢ã‚¹ãƒ•ã‚¡ãƒ«ãƒˆ: {len(asphalt_pcd.points)} ç‚¹")
        
        return white_points_pcd, asphalt_pcd
    
    def extract_white_lines_rgb_fallback(self, pcd):
        """
        RGBé–¾å€¤ã«ã‚ˆã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™½ç·šæ¤œå‡º
        """
        colors = np.asarray(pcd.colors)
        white_mask = np.all(colors > self.config['rgb_threshold'], axis=1)
        
        white_points_pcd = pcd.select_by_index(np.where(white_mask)[0])
        asphalt_pcd = pcd.select_by_index(np.where(~white_mask)[0])
        
        print(f"RGBç™½ç·šæ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯): {len(white_points_pcd.points)} ç‚¹")
        
        return white_points_pcd, asphalt_pcd
    
    def apply_morphological_processing(self, pcd):
        """
        å½¢æ…‹å­¦çš„å‡¦ç†ã«ã‚ˆã‚‹ç‚¹ç¾¤æ•´å½¢
        """
        print("\n=== STEP 4: å½¢æ…‹å­¦çš„å‡¦ç† ===")
        
        if len(pcd.points) == 0:
            return pcd
        
        # ä¾µé£Ÿå‡¦ç†: å­¤ç«‹ç‚¹ã‚„ãƒã‚¤ã‚ºã‚’é™¤å»
        kdtree = o3d.geometry.KDTreeFlann(pcd)
        erosion_indices = []
        
        for i, point in enumerate(pcd.points):
            [k, idx, _] = kdtree.search_radius_vector_3d(point, self.config['morphology']['erosion_radius'])
            if k >= self.config['morphology']['erosion_neighbors']:
                erosion_indices.append(i)
        
        eroded_pcd = pcd.select_by_index(erosion_indices)
        
        # è†¨å¼µå‡¦ç†: é€£ç¶šæ€§ã‚’å›å¾©
        if len(eroded_pcd.points) == 0:
            return eroded_pcd
        
        kdtree_original = o3d.geometry.KDTreeFlann(pcd)
        dilation_indices = set()
        
        for point in eroded_pcd.points:
            [k, idx_list, _] = kdtree_original.search_radius_vector_3d(point, self.config['morphology']['dilation_radius'])
            dilation_indices.update(idx_list)
        
        processed_pcd = pcd.select_by_index(list(dilation_indices))
        
        print(f"å½¢æ…‹å­¦çš„å‡¦ç†å¾Œ: {len(processed_pcd.points)} ç‚¹")
        
        return processed_pcd
    
    def cluster_and_vectorize(self, pcd):
        """
        ç‚¹ç¾¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        """
        print("\n=== STEP 5: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ– ===")
        
        if len(pcd.points) == 0:
            return [], []
        
        points = np.asarray(pcd.points)
        points_2d = points[:, :2]  # XYå¹³é¢ã§ã®å‡¦ç†
        
        # DBSCANã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        clustering = DBSCAN(
            eps=self.config['clustering']['eps'],
            min_samples=self.config['clustering']['min_samples']
        ).fit(points_2d)
        
        labels = clustering.labels_
        unique_labels = set(labels)
        
        lines = []
        shapes = []
        
        for label in unique_labels:
            if label == -1:  # ãƒã‚¤ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue
            
            cluster_points = points_2d[labels == label]
            
            if len(cluster_points) < 10:
                continue
            
            # ç·šå½¢æ€§ã®åˆ¤å®š
            linearity = self.calculate_linearity(cluster_points)
            
            if linearity > self.config['vectorization']['linearity_threshold']:
                # ç›´ç·šã¨ã—ã¦å‡¦ç†
                line = self.fit_line_to_cluster(cluster_points)
                if line and self.calculate_line_length(line) > self.config['vectorization']['min_length']:
                    lines.append(line)
            else:
                # å½¢çŠ¶ã¨ã—ã¦å‡¦ç†
                shape = self.create_shape_from_cluster(cluster_points)
                if shape:
                    shapes.append(shape)
        
        print(f"æŠ½å‡ºçµæœ: ç·šåˆ† {len(lines)}æœ¬, å½¢çŠ¶ {len(shapes)}å€‹")
        
        return lines, shapes
    
    def calculate_linearity(self, points):
        """
        ç‚¹ç¾¤ã®ç·šå½¢æ€§ã‚’è¨ˆç®—
        """
        if len(points) < 3:
            return 0.0
        
        pca = PCA(n_components=2)
        pca.fit(points)
        
        explained_variance_ratio = pca.explained_variance_ratio_
        linearity_score = explained_variance_ratio[0] / sum(explained_variance_ratio)
        
        return linearity_score
    
    def fit_line_to_cluster(self, points):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ç›´ç·šã‚’æŠ½å‡º
        """
        if len(points) < 2:
            return None
        
        # PCAã§ä¸»è»¸ã‚’æ±‚ã‚ã‚‹
        pca = PCA(n_components=2)
        pca.fit(points)
        
        center = np.mean(points, axis=0)
        direction = pca.components_[0]
        
        # æŠ•å½±è·é›¢ã®ç¯„å›²ã‚’æ±‚ã‚ã‚‹
        projections = (points - center).dot(direction)
        min_proj, max_proj = projections.min(), projections.max()
        
        # ç·šåˆ†ã®ç«¯ç‚¹ã‚’è¨ˆç®—
        start_point = center + min_proj * direction
        end_point = center + max_proj * direction
        
        return (tuple(start_point), tuple(end_point))
    
    def calculate_line_length(self, line):
        """
        ç·šåˆ†ã®é•·ã•ã‚’è¨ˆç®—
        """
        start, end = line
        return np.linalg.norm(np.array(end) - np.array(start))
    
    def create_shape_from_cluster(self, points):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰å½¢çŠ¶ã‚’ä½œæˆ
        """
        if len(points) < 4:
            return None
        
        # Alpha shapeã§å¢ƒç•Œã‚’ä½œæˆ
        try:
            alpha_shape = alphashape.alphashape(points, 0.5)
            if isinstance(alpha_shape, Polygon):
                return list(alpha_shape.exterior.coords)
        except:
            pass
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å‡¸åŒ…
        from scipy.spatial import ConvexHull
        try:
            hull = ConvexHull(points)
            return [tuple(points[i]) for i in hull.vertices]
        except:
            return None
    
    def classify_road_markings(self, lines, shapes):
        """
        é“è·¯æ¨™ç¤ºã®åˆ†é¡ï¼ˆæ¨ªæ–­æ­©é“ã€åœæ­¢ç·šã€è»Šç·šç­‰ï¼‰
        """
        print("\n=== STEP 6: é“è·¯æ¨™ç¤ºåˆ†é¡ ===")
        
        crosswalks = []
        stop_lines = []
        lanes = []
        
        # å½¢çŠ¶ã‹ã‚‰æ¨ªæ–­æ­©é“ã‚’æ¤œå‡º
        for shape in shapes:
            if self.is_crosswalk_shape(shape):
                crosswalks.append(shape)
        
        # ç·šåˆ†ã‹ã‚‰åœæ­¢ç·šã¨è»Šç·šã‚’åˆ†é¡
        for line in lines:
            if self.is_stop_line(line, crosswalks):
                stop_lines.append(line)
            else:
                lanes.append(line)
        
        print(f"åˆ†é¡çµæœ: æ¨ªæ–­æ­©é“ {len(crosswalks)}å€‹, åœæ­¢ç·š {len(stop_lines)}æœ¬, è»Šç·š {len(lanes)}æœ¬")
        
        return crosswalks, stop_lines, lanes
    
    def is_crosswalk_shape(self, shape):
        """
        æ¨ªæ–­æ­©é“å½¢çŠ¶ã®åˆ¤å®š
        """
        if len(shape) < 4:
            return False
        
        # çŸ©å½¢ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ãƒã‚§ãƒƒã‚¯
        points = np.array(shape)
        rect = cv2.minAreaRect(points.astype(np.float32))
        (_, (w, h), _) = rect
        
        if min(w, h) == 0:
            return False
        
        aspect_ratio = max(w, h) / min(w, h)
        
        return (self.config['classification']['crosswalk_min_aspect_ratio'] < 
                aspect_ratio < 
                self.config['classification']['crosswalk_max_aspect_ratio'])
    
    def is_stop_line(self, line, crosswalks):
        """
        åœæ­¢ç·šã®åˆ¤å®š
        """
        # ç·šåˆ†ã®é•·ã•ã¨ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ãƒã‚§ãƒƒã‚¯
        length = self.calculate_line_length(line)
        
        # éå¸¸ã«çŸ­ã„ç·šåˆ†ã¯åœæ­¢ç·šã§ã¯ãªã„
        if length < 2.0:
            return False
        
        # æ¨ªæ–­æ­©é“ã¨ã®ä½ç½®é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
        line_center = np.array([(line[0][0] + line[1][0]) / 2, 
                               (line[0][1] + line[1][1]) / 2])
        
        for crosswalk in crosswalks:
            crosswalk_center = np.mean(np.array(crosswalk), axis=0)
            distance = np.linalg.norm(line_center - crosswalk_center)
            
            if distance < self.config['classification']['stop_line_distance_threshold']:
                # è§’åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆæ¨ªæ–­æ­©é“ã«å¯¾ã—ã¦å‚ç›´ã‹ã©ã†ã‹ï¼‰
                return self.check_perpendicular_to_crosswalk(line, crosswalk)
        
        return False
    
    def check_perpendicular_to_crosswalk(self, line, crosswalk):
        """
        åœæ­¢ç·šãŒæ¨ªæ–­æ­©é“ã«å¯¾ã—ã¦å‚ç›´ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
        """
        # ç·šåˆ†ã®æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
        line_vector = np.array(line[1]) - np.array(line[0])
        line_angle = np.rad2deg(np.arctan2(line_vector[1], line_vector[0])) % 180
        
        # æ¨ªæ–­æ­©é“ã®ä¸»è¦æ–¹å‘ã‚’è¨ˆç®—
        crosswalk_points = np.array(crosswalk)
        pca = PCA(n_components=2)
        pca.fit(crosswalk_points)
        crosswalk_vector = pca.components_[0]
        crosswalk_angle = np.rad2deg(np.arctan2(crosswalk_vector[1], crosswalk_vector[0])) % 180
        
        # è§’åº¦å·®ã‚’è¨ˆç®—
        angle_diff = abs(line_angle - crosswalk_angle)
        angle_diff = min(angle_diff, 180 - angle_diff)
        
        # å‚ç›´ã«è¿‘ã„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ90åº¦Â±è¨±å®¹ç¯„å›²ï¼‰
        return (90 - self.config['classification']['stop_line_angle_tolerance'] < 
                angle_diff < 
                90 + self.config['classification']['stop_line_angle_tolerance'])
    
    def save_to_dxf(self, crosswalks, stop_lines, lanes, curb_lines, output_path):
        """
        åˆ†é¡ã•ã‚ŒãŸé“è·¯æ¨™ç¤ºã‚’DXFãƒ•ã‚¡ã‚¤ãƒ«ã«è‰²åˆ†ã‘ã—ã¦ä¿å­˜
        """
        print("\n=== STEP 7: DXFä¿å­˜ï¼ˆè‰²åˆ†ã‘ï¼‰===")
        
        doc = ezdxf.new("R2010", setup=True)
        msp = doc.modelspace()
        
        # ãƒ¬ã‚¤ãƒ¤ãƒ¼å®šç¾©
        layers_config = self.config['dxf_layers']
        for layer_key, layer_info in layers_config.items():
            doc.layers.add(name=layer_info['name'], color=layer_info['color'])
        
        # æ¨ªæ–­æ­©é“ã®æç”»ï¼ˆãƒã‚¼ãƒ³ã‚¿ï¼‰
        for crosswalk in crosswalks:
            points_3d = [(p[0], p[1], 0.0) for p in crosswalk]
            msp.add_lwpolyline(points_3d, close=True, 
                             dxfattribs={"layer": layers_config['crosswalk']['name']})
        
        # åœæ­¢ç·šã®æç”»ï¼ˆé»„è‰²ï¼‰
        for stop_line in stop_lines:
            start_3d = (stop_line[0][0], stop_line[0][1], 0.0)
            end_3d = (stop_line[1][0], stop_line[1][1], 0.0)
            msp.add_line(start_3d, end_3d, 
                        dxfattribs={"layer": layers_config['stop_line']['name']})
        
        # è»Šç·š/æ­©é“ç·šã®æç”»ï¼ˆç·‘è‰²ï¼‰
        for lane in lanes:
            start_3d = (lane[0][0], lane[0][1], 0.0)
            end_3d = (lane[1][0], lane[1][1], 0.0)
            msp.add_line(start_3d, end_3d, 
                        dxfattribs={"layer": layers_config['lane']['name']})
        
        # ç¸çŸ³ã®æç”»ï¼ˆèµ¤è‰²ï¼‰
        for curb_line in curb_lines:
            start_3d = (curb_line[0][0], curb_line[0][1], 0.0)
            end_3d = (curb_line[1][0], curb_line[1][1], 0.0)
            msp.add_line(start_3d, end_3d, 
                        dxfattribs={"layer": layers_config['curb']['name']})
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚­ã‚¹ãƒˆã®è¿½åŠ 
        metadata_text = f"Road Marking Classification Results\\næ¨ªæ–­æ­©é“: {len(crosswalks)}å€‹\\nåœæ­¢ç·š: {len(stop_lines)}æœ¬\\nè»Šç·š: {len(lanes)}æœ¬\\nç¸çŸ³: {len(curb_lines)}æœ¬\\nä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        msp.add_text(
            metadata_text,
            dxfattribs={
                "layer": layers_config['metadata']['name'],
                "insert": (0, 0, 0),
                "height": 1.0,
                "style": "Standard"
            }
        )
        
        try:
            doc.saveas(output_path)
            print(f"âœ… è‰²åˆ†ã‘DXFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: '{output_path}'")
            print(f"   æ¨ªæ–­æ­©é“: {len(crosswalks)}å€‹, åœæ­¢ç·š: {len(stop_lines)}æœ¬, è»Šç·š: {len(lanes)}æœ¬, ç¸çŸ³: {len(curb_lines)}æœ¬")
        except Exception as e:
            print(f"âŒ DXFä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def process_pcd_file(self, input_path, output_path):
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        """
        print(f"\n{'='*60}")
        print(f"é“è·¯æ¨™ç¤ºåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - å‡¦ç†é–‹å§‹")
        print(f"å…¥åŠ›: {input_path}")
        print(f"å‡ºåŠ›: {output_path}")
        print(f"{'='*60}")
        
        if not os.path.exists(input_path):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {input_path}")
            return None
        
        # ç‚¹ç¾¤èª­ã¿è¾¼ã¿
        pcd = o3d.io.read_point_cloud(input_path)
        print(f"ç‚¹ç¾¤èª­ã¿è¾¼ã¿å®Œäº†: {len(pcd.points)} ç‚¹")
        
        if not pcd.has_colors():
            print("âš ï¸ è­¦å‘Š: ã‚«ãƒ©ãƒ¼æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: RANSACé“è·¯å¹³é¢æ¤œå‡º
            plane_model, road_layer_pcd = self.detect_road_plane(pcd)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ç›¸å¯¾é«˜ã•ã«ã‚ˆã‚‹åˆ†é¡
            road_surface_pcd, curbs_pcd = self.classify_by_height(road_layer_pcd, plane_model)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ç™½ç·šæ¤œå‡ºï¼ˆHSVå„ªå…ˆã€RGBãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            white_lines_pcd, asphalt_pcd = self.extract_white_lines_hsv(road_surface_pcd)
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: å½¢æ…‹å­¦çš„å‡¦ç†
            processed_white_pcd = self.apply_morphological_processing(white_lines_pcd)
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            white_lines, white_shapes = self.cluster_and_vectorize(processed_white_pcd)
            
            # ç¸çŸ³ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            curb_lines, _ = self.cluster_and_vectorize(curbs_pcd)
            
            # ã‚¹ãƒ†ãƒƒãƒ—6: é“è·¯æ¨™ç¤ºåˆ†é¡
            crosswalks, stop_lines, lanes = self.classify_road_markings(white_lines, white_shapes)
            
            # ã‚¹ãƒ†ãƒƒãƒ—7: DXFä¿å­˜
            self.save_to_dxf(crosswalks, stop_lines, lanes, curb_lines, output_path)
            
            print(f"\nğŸ‰ å‡¦ç†å®Œäº†!")
            
            return {
                'crosswalks': crosswalks,
                'stop_lines': stop_lines,
                'lanes': lanes,
                'curb_lines': curb_lines,
                'road_surface_points': len(road_surface_pcd.points),
                'white_points': len(processed_white_pcd.points),
                'curb_points': len(curbs_pcd.points)
            }
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None


def process_large_dataset(input_dir, output_dir, chunk_size_mb=100):
    """
    å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ300GBç­‰ï¼‰ã®åˆ†å‰²å‡¦ç†
    """
    print("="*60)
    print("å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²å‡¦ç†")
    print("="*60)
    
    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼
    if not os.path.exists(input_dir):
        print(f"âŒ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
        return False
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹æ‹¡å¼µå­
    supported_extensions = ['.pcd', '.ply', '.las', '.laz']
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    input_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in supported_extensions):
                filepath = os.path.join(root, file)
                filesize = os.path.getsize(filepath) / (1024 * 1024)  # MB
                input_files.append((filepath, filesize))
    
    print(f"ç™ºè¦‹ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(input_files)}")
    total_size = sum(size for _, size in input_files)
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size:.1f} MB ({total_size/1024:.1f} GB)")
    
    # åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    extractor = EnhancedWhiteLineExtractor()
    
    # ãƒãƒƒãƒå‡¦ç†
    processed_count = 0
    success_count = 0
    
    for filepath, filesize in input_files:
        filename = os.path.basename(filepath)
        relative_path = os.path.relpath(filepath, input_dir)
        output_file = os.path.join(output_dir, relative_path.replace(os.path.splitext(relative_path)[1], '.dxf'))
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        output_file_dir = os.path.dirname(output_file)
        if not os.path.exists(output_file_dir):
            os.makedirs(output_file_dir)
        
        print(f"\nå‡¦ç†ä¸­ ({processed_count+1}/{len(input_files)}): {filename} ({filesize:.1f}MB)")
        
        try:
            if filesize > chunk_size_mb:
                print(f"âš ï¸ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« ({filesize:.1f}MB) - ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†")
                # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®å‡¦ç†ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç­‰ï¼‰
                result = extractor.process_pcd_file(filepath, output_file)
            else:
                result = extractor.process_pcd_file(filepath, output_file)
            
            if result:
                success_count += 1
                print(f"âœ… å®Œäº†: {filename}")
            else:
                print(f"âŒ å¤±æ•—: {filename}")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {filename} - {e}")
        
        processed_count += 1
        
        # é€²æ—è¡¨ç¤º
        progress = (processed_count / len(input_files)) * 100
        print(f"é€²æ—: {progress:.1f}% ({success_count}/{processed_count} æˆåŠŸ)")
    
    print(f"\nğŸ‰ ãƒãƒƒãƒå‡¦ç†å®Œäº†!")
    print(f"æˆåŠŸ: {success_count}/{processed_count} ãƒ•ã‚¡ã‚¤ãƒ«")
    
    return success_count > 0


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•° - ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    """
    parser = argparse.ArgumentParser(
        description='Road Marking Classifier - é“è·¯æ¨™ç¤ºåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
  python main.py input.pcd output.dxf
  python main.py input.pcd output.dxf --config config.json
  
  # å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†
  python main.py --batch input_dir output_dir
  python main.py --batch input_dir output_dir --chunk-size 200
  
  # ãƒ˜ãƒ«ãƒ—
  python main.py --help

ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹å…¥åŠ›å½¢å¼: .pcd, .ply, .las, .laz
å‡ºåŠ›å½¢å¼: .dxf (è‰²åˆ†ã‘æ¸ˆã¿)

è‰²åˆ†ã‘ãƒ¬ã‚¤ãƒ¤ãƒ¼:
  - CROSSWALK_STRIPES (ãƒã‚¼ãƒ³ã‚¿): æ¨ªæ–­æ­©é“
  - STOP_LINES (é»„è‰²): åœæ­¢ç·š
  - LANES (ç·‘è‰²): è»Šç·š/æ­©é“ç·š
  - CURBS (èµ¤è‰²): ç¸çŸ³
        """
    )
    
    parser.add_argument('input', nargs='?', help='å…¥åŠ›ç‚¹ç¾¤ãƒ•ã‚¡ã‚¤ãƒ« (.pcd, .ply) ã¾ãŸã¯å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (--batchæ™‚)')
    parser.add_argument('output', nargs='?', help='å‡ºåŠ›DXFãƒ•ã‚¡ã‚¤ãƒ« (.dxf) ã¾ãŸã¯å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (--batchæ™‚)')
    parser.add_argument('--config', '-c', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (.json)')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°å‡ºåŠ›')
    parser.add_argument('--batch', '-b', action='store_true', help='ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ï¼‰')
    parser.add_argument('--chunk-size', type=int, default=100, help='å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®šé–¾å€¤ (MB, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100)')
    
    args = parser.parse_args()
    
    # ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰
    if args.batch:
        if not args.input or not args.output:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§ã¯å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
            print("ä½¿ç”¨ä¾‹: python main.py --batch input_dir output_dir")
            return 1
        
        success = process_large_dataset(args.input, args.output, args.chunk_size)
        return 0 if success else 1
    
    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
    if not args.input or not args.output:
        print("âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
        print("ä½¿ç”¨ä¾‹: python main.py input.pcd output.dxf")
        return 1
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(args.input):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input}")
        return 1
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    extractor = EnhancedWhiteLineExtractor(config_path=args.config)
    
    # å‡¦ç†å®Ÿè¡Œ
    result = extractor.process_pcd_file(args.input, args.output)
    
    if result:
        print(f"\nâœ… å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        if args.verbose:
            print(f"è©³ç´°çµæœ:")
            for key, value in result.items():
                if isinstance(value, list):
                    print(f"  {key}: {len(value)}å€‹")
                else:
                    print(f"  {key}: {value}")
        return 0
    else:
        print(f"\nâŒ å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return 1


if __name__ == "__main__":
    exit(main())